---
title: "Stat 420 Data Analysis Project: <br> Modeling Used Car Pricing"
output: 
  html_document:
    theme: readable
  pdf_document: default
urlcolor: cyan
---

<style>
h1.title {
  text-align: center;
  margin-top: 50px;
}
div.author {
  text-align: center;
}
</style>

<div class="author">
Max Piazza <br> David Orona <br> Nithya Arumugam <br> Abhitej Bokka
</div>

## Introduction

In an ever-volatile market where every dollar counts, the used car market represents a critical sector of the consumer industry. With rising consumer demand and an increasing variety of vehicles entering the secondary market, understanding the factors that influence used car prices is essential. Buyers seek to make informed decisions based on value for money, while sellers aim to maximize returns by accurately pricing their vehicles. Bridging this gap requires a data-driven approach to uncover the relationships between vehicle specifications and market pricing.

This project utilizes the “Vehicle dataset” by Nehal Birla, Nishant Verma, and Nikhil Kushwaha, available on Kaggle at [https://www.kaggle.com/datasets/nehalbirla/vehicle-dataset-from-cardekho/data?select=Car+details+v3.csv](https://www.kaggle.com/datasets/nehalbirla/vehicle-dataset-from-cardekho/data?select=Car+details+v3.csv).

This dataset aggregates detailed information on over 10,000 used cars, including key variables such as fuel type, transmission, engine capacity, mileage, and kilometers driven, alongside categorical variables like seller type, ownership history, and geographic location. 

Our analysis is driven by three core objectives:

* To model the relationship between vehicle specifications (e.g., fuel efficiency, transmission, and fuel type) and their pricing.
* To identify regional trends and seller-specific factors influencing market prices.
* To evaluate how performance metrics, such as engine power and fuel efficiency, impact purchasing behavior.

<!-- Once we know what exactly what "statistical modeling techniques" we use, we can refer to them properly in this introduction, for now I just have "regression analysis"  -->

Using statistical modeling techniques, including regression analysis, we aim to deliver a robust and interpretable model that not only predicts car prices but also highlights the most influential factors driving price variations. Our results will shed light on market dynamics, offering actionable insights for both consumers and industry professionals navigating this volatile space.

By the conclusion of this project, we aim to provide a detailed analysis that enhances understanding of the used car market, aiding stakeholders in making informed decisions in an ever-changing economic landscape.


The dataset contains the following attributes: 

|    | Attribute Name       | Description                                                                        |
|----|------------------|------------------------------------------------------------------------------------|
| 1  |   `name`           |   The make and model of the vehicle (e.g., Hyundai i10, Honda City).                   |
| 2  |   `year`           |   The year the vehicle was manufactured.                                           |
| 3  |   `selling_price`  |   The selling price of the vehicle in Indian Rupees (INR).                                               |
| 4  |   `km_driven`      |   The total distance the vehicle has been driven (in km).                                  |
| 5  |   `fuel`           |   The type of fuel used by the vehicle ("Diesel", "Petrol", "LPG", or "CNG").                        |
| 6  |   `seller_type`    |   The type of seller ("Individual", "Dealer" or "Trustmark Dealer").                                     |
| 7  |   `transmission`   |   The type of transmission system ("Manual" or "Automatic").                         |
| 8  |   `owner`          |   The number of previous owners of the vehicle ("First Owner", "Second Owner", "Third Owner", "Fourth and Above Owner", or "Test Drive Car").  |
| 9  |   `mileage`        |   The fuel efficiency of the vehicle (in either km/l or km/kg).                           |
| 10 |   `engine`         |   The engine displacement capacity (in CC).                                         |
| 11 |   `max_power`      |   The maximum power output of the vehicle’s engine, measured in brake horsepower (bhp).|
| 12 |   `torque`         |   A pair of torque and RPM values representing the max torque of the vehicle. The torque values are in either Nm or kgm, and the RPM values are either values or value ranges.                                                              |
| 13 |   `seats`          |   The seating capacity of the vehicle as an integer.                   |
|    |                  |                                                                                    |

The above attributes can be categorized into numeric and categorical variables. Numeric variables can be separated into discrete and continuous variables. 

| Attribute Type               | Attribute Name                                    |
|------------------------------|---------------------------------------------------|
| Categorical Variables        | `name`, `fuel`, `seller_type`, `transmission`, `owner`      |
| Discrete Numeric Variables   | `year`, `km_driven`, `seats`                            |
| Continuous Numeric Variables | `selling_price`, `mileage`, `engine`, `max_power`, `torque` |

## Methods 
```{r include=FALSE}
# Load required R packages
library(readr)
library(stringr)
library(car)
library(lmtest)
```

```{r}
# Set document-wide options 
options(tibble.width = Inf)  # Make tibbles display all columns
```

### Load dataset
```{r message=FALSE}
car_details = read_csv("Car details v3.csv")
```

### Total number of observations
```{r}
nrow(car_details)
```

### Sample of data from Vehicle dataset
```{r}
head(car_details)
```

### Data cleaning
#### Excluding missing values from dataset
```{r eval=FALSE, include=FALSE}
col_name=""
for(col_name in names(car_details))
{
  if(sum(is.na(car_details[col_name]))>0)
  {
    print(c(col_name,":",sum(is.na(car_details[col_name]))))
  }
}
```

```{r echo=TRUE}
car_details = na.omit(car_details)
nrow(car_details)
```

#### Excluding duplicate rows from dataset
```{r}
sum(duplicated(car_details))
car_details = car_details[!duplicated(car_details),]
nrow(car_details)
```

#### Transforming ```name``` variable
```{r}
# Extract the first word from "name" to get the make of the vehicle
car_details$name = word(car_details$name,1)
# Rename "name" variable to "make"
colnames(car_details)[1] = "make"
# Change datatypes of "make" from character to factor
car_details$make = as.factor(car_details$make)
```

#### Transforming ```mileage``` variable
```{r}
# View raw data for "mileage" variable
head(car_details$mileage, n=20)
# Drop 86 rows where "mileage" value contains the text "km/kg"
car_details <- car_details[!grepl("km/kg", car_details$mileage), ]
# Extract the numeric value from "mileage" 
car_details$mileage = word(car_details$mileage,1)
# Change data_type of "mileage" from character to numeric
car_details$mileage=as.numeric(car_details$mileage)

# Rename "mileage" to "fuel_efficiency"
colnames(car_details)[which(names(car_details) == "mileage")] = "fuel_efficiency"

# View new data for "fuel_efficiency" variable
head(car_details$fuel_efficiency, n=20)
```
Above, the ```mileage``` variable is renamed to ```fuel_efficiency``` to prevent confusion with the ```km_driven``` variable, which represents the quantity normally referred to as vehicle "mileage". 

#### Transforming ```engine``` variable
```{r}
# View raw data for "engine" variable
head(car_details$engine, n=20)
# Extract the numeric value from each entry (remove the text "CC" from the end of each entry)
car_details$engine = word(car_details$engine,1)
# Change data_type of "engine" from character to numeric
car_details$engine=as.numeric(car_details$engine)
# View new data for "engine" variable
head(car_details$engine, n=20)
```

#### Transforming ```max_power``` variable
```{r}
# Transform "max_power" variable
# View raw data for "max_power" variable
head(car_details$max_power, n=20)
# Extract the numeric value from each entry of "max_power" (remove the text "bhp" from the end of each entry)
car_details$max_power = word(car_details$max_power,1)
# Change data_type of "max_power" from character to numeric
car_details$max_power=as.numeric(car_details$max_power)
# View new data for "max_power" variable
head(car_details$max_power, n=20)
```

#### Converting character-typed columns to factor type
```{r}
# Change datatypes of "fuel", "seller_type", "transmission", and "owner"
# from character to factor 
car_details$fuel=as.factor(car_details$fuel)
car_details$seller_type=as.factor(car_details$seller_type)
car_details$transmission=as.factor(car_details$transmission)
car_details$owner=as.factor(car_details$owner)
```

#### Converting ```km_driven``` to ```km_driven_in_10k```
```{r}
# Modify the "km_driven" column by dividing the values of each entry by 10,000 and renaming the column to "km_driven_in_10k" 
car_details$km_driven = car_details$km_driven/10000
# Rename km_driven
colnames(car_details)[4]="km_driven_in_10k"
# View data for "km_driven_in_10k" column
head(car_details)[4]
```

#### Converting ```selling_price``` to ```selling_price_in_10k```
```{r}
# Modify "selling_price" column by dividing the values of each entry by 10,000 and renaming the column to "selling_price_in_10k"
car_details$selling_price = car_details$selling_price/10000
# Rename selling_price to "selling_price_in_10k"
colnames(car_details)[3]="selling_price_in_10k"
# View data for "selling_price_in_10k" column
head(car_details)[3]

```

#### Dropping ```torque``` column
```{r}
# Drop "torque" column
car_details = car_details[,!names(car_details) %in% "torque"]
```

#### Creating ```make_category``` variable from ```make``` variable
```{r}
unique(car_details$make)
```

- From the above result we can see that there are 31 unique values for "make".
- When we model the data using the independent variable "make", there will be at least 30 dummy variables as predictors.
- To reduce the model complexity and to increase interpretability, the car make can be grouped into broader categories as "Budget", "Mid-Range" or "Luxury" depending on general market perception.

<!-- By the code below: 
"Budget" cars are Maruti, Tata, Mahindra, Datsun, Renault, Chevrolet, Fiat, Daewoo, Ambassador, and Ashok.
"Midrange" cars are Honda, Ford, Hyundai, Toyota, Volkswagen, Nissan, Skoda, Mitsubishi, Force, Kia, and MG.
"Luxury" cars are Jeep, Mercedes-Benz, Audi, BMW, Lexus, Jaguar, Land, Volvo, Isuzu, and Opel. 

There could be some potential errors. For example, Jeeps and Opels are not normally luxury. Chevrolet could be luxury (e.g. Corvette). -->

```{r}
# Create new column "make_category" from "make" column
car_details$make_category = ifelse(car_details$make %in% 
  c("Ambassador", "Ashok", "Daewoo", "Datsun", "Opel", "Fiat"), 
  "Budget",
  ifelse(car_details$make %in% 
           c("Chevrolet", "Maruti", "Renault", "Mitsubishi", "Ford", 
             "Honda", "Hyundai", "Isuzu", "Kia", "Toyota", "Force", 
             "Volkswagen", "Tata", "Skoda", "Jeep", "MG", "Nissan", "Mahindra"), 
         "Midrange", 
         "Luxury"
  )
)

# Convert make_category to a factor
car_details$make_category = as.factor(car_details$make_category)

# Output all levels of the make_category variable
levels(car_details$make_category)

# Create a summary table of makes and their categories and view the mapping
make_category_mapping <- unique(car_details[, c("make", "make_category")])
make_category_mapping_df <- as.data.frame(make_category_mapping)
print(make_category_mapping_df, row.names = FALSE)  
```

#### Final structure of the ```car_details``` dataset 

| Attribute Name         | Description                                                                                                  | Variable Type |
|-------------------------|--------------------------------------------------------------------------------------------------------------|---------------|
| `make`                | The manufacturer of the vehicle (e.g., Maruti, Hyundai, Honda, etc.).                                       | Factor        |
| `year`                | The year the vehicle was manufactured.                                                                      | Numeric       |
| `selling_price_in_10k` | The selling price of the vehicle in ten-thousands of Indian Rupees (INR).                                   | Numeric       |
| `km_driven_in_10k`    | The total distance the vehicle has been driven, measured in ten-thousands of kilometers.                    | Numeric       |
| `fuel`                | The type of fuel used by the vehicle ("Diesel", "Petrol", "LPG", or "CNG").                                 | Factor        |
| `seller_type`         | The type of seller ("Individual", "Dealer", or "Trustmark Dealer").                                         | Factor        |
| `transmission`        | The type of transmission system ("Manual" or "Automatic").                                                 | Factor        |
| `owner`               | The number of previous owners of the vehicle ("First Owner", "Second Owner", "Third Owner", "Fourth and Above Owner", or "Test Drive Car").                        | Factor        |
| `fuel_efficiency`     | The fuel efficiency of the vehicle in km/l.          | Numeric       |
| `engine`              | The engine displacement capacity of the vehicle, measured in cubic centimeters (CC).                       | Numeric       |
| `max_power`           | The maximum power output of the vehicle's engine, measured in brake horsepower (BHP).                      | Numeric       |
| `seats`               | The seating capacity of the vehicle.                                                                       | Numeric       |
| `make_category`       | Categorized vehicle make (e.g., "Luxury", "Midrange", or "Budget").                                         | Factor        |

#### Sample of final dataset
```{r}
head(car_details, n=8)
```


### Data Analysis

#### Variable Distribution Analysis
```{r}
car_details$selling_price_in_10k[car_details$selling_price_in_10k > 720]
car_details=subset(car_details,subset = car_details$selling_price_in_10k < 720,)
```
- There is one observation, which is quite different from the general pattern of selling price. This can impact the model that we build, hence excluded one observation with ```selling_price``` = 1000. 

##### Selling Price distribution
```{r}
# Histogram of selling prices 
hist(car_details$selling_price_in_10k,xlab="Selling Price (in 10,000 INR)",
     main="Selling Price distribution",
     breaks = 30, 
     col = "lightblue")
```

- The above plot is positively skewed, meaning the selling prices for most of the observations are less than or equal to 2 million INR, and there are much fewer observations with selling prices above this amount. 

##### Frequency Distribution of Categorical Variables
```{r}
make_counts = table(car_details$make)
fuel_type_car_count = table(car_details$fuel)
seller_type_car_count = table(car_details$seller_type)
trans_type_car_count = table(car_details$transmission)
owner_type_car_count = table(car_details$owner)

par(mfrow = c(2, 3))
# Plot 1: Number of cars by make
barplot(sort(make_counts),horiz=TRUE, las = 1,
        xlab = "Number of Cars",
        ylab = "Car Make",
        col = "lightblue",
        cex.names = 0.5,
        main = "Num. of Cars in Each Make")

# Plot 2: Number of cars by fuel type
barplot(sort(fuel_type_car_count), horiz = TRUE, las = 1, cex.names = 0.9,
        xlab = "Number of Cars",col = "lightblue", main = "Num. of Cars in Each Fuel Type")

# Plot 3: Number of cars by seller type
barplot(sort(seller_type_car_count), horiz = TRUE, las = 1, cex.names = 0.8,
        xlab = "Number of Cars",col = "lightblue", main = "Num. of Cars in Each Seller Type")

# Plot 4: Number of cars by transmission type
barplot(sort(trans_type_car_count), horiz = TRUE, las = 1, cex.names = 0.8,
        xlab = "Number of Cars",col = "lightblue", main = "Num. of Cars in Each Trans Type")

# Plot 5: Number of cars by owner type
barplot(sort(owner_type_car_count), horiz = TRUE, las = 1, cex.names = 0.6,
        xlab = "Number of Cars",col = "lightblue", main = "Num. of Cars in Each Owner Type")
```

##### Boxplots of Selling Price by Different Categorical Variables

###### Selling Price by Car Make
```{r}
# Boxplot of selling price by car make
boxplot(selling_price_in_10k ~ make, data = car_details,col=rainbow(length(unique(car_details$make))),
        las = 2,cex.axis = 0.7,               
        main = "Boxplot of Selling Price by Car Make",
        xlab = "Car Make",
        ylab = "Selling Price (10,000 INR)")
```

- The above boxplots indicates a significant variation in selling prices across different car makes. Some brands have much wider price ranges than others. 
- Brands like Mercedes-Benz, BMW, Jaguar, Land Rover and Volvo have the highest median selling prices, while cars like Tata, Maruti, and Daewoo have the lowest median selling prices.

###### Selling Price by Fuel Type
```{r}
# Boxplot of selling price by fuel type
boxplot(selling_price_in_10k ~ fuel, data = car_details, cex.axis = 0.8,
        col = rainbow(length(unique(car_details$fuel))),
        main = "Box Plot of Selling Price by Fuel Type",
        xlab = "Fuel Type", ylab = "Selling Price (10,000 INR)")
```

- From the above boxplot we can see that the median selling price of Diesel cars are slightly higher than the median selling price of Petrol cars.

###### Selling Price by Seller Type
```{r}
# Boxplot of selling price by seller type
boxplot(selling_price_in_10k ~ seller_type, data = car_details, cex.axis = 0.6,
        col = rainbow(length(unique(car_details$seller_type))),
        main = "Box Plot of Selling Price by Seller Type",
        xlab = "Seller Type", ylab = "Selling Price (10,000 INR)")
```

- The cars sold by Individuals have the lowest median cost when compared to cars sold by dealers.
 
###### Selling Price by Transmission Type
```{r}
# Boxplot of selling price by transmission type
plot(selling_price_in_10k ~ transmission, data = car_details,
     col = rainbow(length(unique(car_details$transmission))),
     main = "Boxplot of Selling Price by Transmission Type",
     xlab = "Transmission Type", 
     ylab = "Selling Price (10,000 INR)")
```

- We can see that there is a difference in the selling price of the Automatic and Manual transmission cars. The cost range of Automatic transmission cars is higher than that of Manual transmission cars. 

###### Selling Price by Owner Type
```{r}
# Boxplot of selling price by owner type
plot(selling_price_in_10k ~ owner, data = car_details, las = 2, cex.axis = 0.5,
     col = rainbow(length(unique(car_details$owner))),
     main = "Boxplot of Selling Price vs Owner Type",
     xlab = "Owner Type", 
     ylab = "Selling Price (10,000 INR)")
```

- The selling prices of cars across different owner types are significantly different. 
- The median price of test drive cars are very high and the rest of the owner types have low median cost
- The median selling price is in the decreasing order of First Owner, Second Owner, Third Owner, Fourth & above Owner.


#### Scatter Plots of Selling Price vs Different Numerical Variables

##### Selling Price vs Year and Transmission Type
```{r}
# Scatter plot of selling price vs year and transmission type
colours = ifelse(car_details$transmission == "Automatic", "blue", "red")
plot(selling_price_in_10k ~ year,data=car_details,col=colours,pch=19,
     main = "Selling Price vs Year and Transmission Type",
     xlab = "Year",
     ylab = "Selling Price (10,000 INR)")
legend("topleft", legend = c("Automatic", "Manual"),
       col = c("blue", "red"), pch = 19)
```

- We can see a **positive correlation between year and selling price.** As the year increases, the selling price is increasing. 
- This suggests that newer cars are priced higher than older ones.
- We can also see that **automatic transmission cars have a higher selling price across all years.** 

##### Selling Price vs Year and Make Category
```{r}
# Scatter plot of selling price vs year and make category
colours = c("Budget" = "blue", "Midrange"="green","Luxury"= "orange")
plot(selling_price_in_10k ~ year,data=car_details,
     col = colours[car_details$make_category],pch=19,
     main = "Selling Price vs Year and Make Category",
     xlab = "Year",
     ylab = "Selling Price (10,000 INR)")
legend("topleft", legend = c("Budget","Midrange","Luxury"),
       col = c("blue", "green","orange"), pch = 19)
```

- Similar to previous plot, there is a positive correlation between year and selling price.
- We see that **cost of Budget cars, mid range cars and luxury car increases with Year.**

##### Selling Price vs Km Driven
```{r}
# Scatter plot of selling price vs km driven
plot(selling_price_in_10k ~ km_driven_in_10k, data=car_details,
     xlab="Km Driven (10,000 km)",
     ylab="Selling Price (10,000 INR)",
     main="Selling Price vs Km Driven")

# Subset out extreme values
car_details = subset(car_details,car_details$km_driven_in_10k < 100,)

# Scatter plot of selling price vs km driven after removing extreme values
plot(selling_price_in_10k ~ km_driven_in_10k, data=car_details,
     xlab="Km Driven (10,000 km)",
     ylab="Selling Price (10,000 INR)",
     main="Selling Price vs Km Driven (extreme values removed)")
```

- The relationship between selling price and kilometers driven doesn't seem to be strongly linear.
- But we can see that **as km driven increases, the selling price remains in low range.** 
- There are 2 observations which are different from the general pattern with values of km driven (150.0000 236.0457). This can been seen in the above plot.
- These observations can impact the model. Hence those two data points are excluded from the second plot.

##### Selling Price vs Fuel Efficiency
```{r}

# Subset out 15 observations with fuel_efficiency=0 
car_details = subset(car_details, car_details$fuel_efficiency!=0,)

# Scatter plot of selling price vs fuel efficiency
plot(selling_price_in_10k ~ fuel_efficiency, data=car_details,
     xlab="Fuel Efficiency (km/l)",
     ylab="Selling Price (10,000 INR)",
     main="Selling Price vs Fuel Efficiency")
```

- Most data points are clustered at fuel efficiency values of 10 to 30 km/l, and there doesn't seem to be a linear relationship.
- That is **higher fuel efficiency doesn't indicate higher selling price.**

##### Selling Price vs Engine Displacement
```{r echo=FALSE}
# Scatter plot of selling price vs engine displacement
plot(selling_price_in_10k ~ engine, data=car_details,
     main="Selling Price vs Engine Displacement",
     ylab="Selling Price (10,000 INR)",
     xlab="Engine Displacement (CC)"
     )
```

- From the above plot, we can see that the **selling price is high for higher values of engine power**

##### Selling Price vs Max Power
```{r}
# Scatter plot of selling price vs max power (by fuel type)
colours = c("Petrol" = "blue", "Diesel"="green")
plot(selling_price_in_10k ~ max_power, data=car_details,
     col=colours[car_details$fuel],
     main="Selling Price vs Max Power (by Fuel Type)",
     xlab="Max Power (bhp)",
     ylab="Selling Price (10,000 INR)" )
legend("topleft", legend = c("Petrol","Diesel"),
       col = c("blue", "green"), pch = 19)
```

- From the above plot, we can see that the there is a linear relationship between max power and selling price.
- We can conclude that **when the maximum power increases, the selling price of the car increases**
- In general, we see that diesel-powered cars have higher selling prices. 
  - But in the above plot, we see that petrol-powered cars with higher horsepower have higher selling prices. 

##### Conclusions of Variable Distribution Analysis

- The selling price distribution is positively skewed. Positively skewed data has extreme values which makes it hard to fit models. 
  - Hence, logarithmic transformation can make the selling price distribution to be normally distributed. 
  - Logarithmic transformations can also help stabilize the variance, making the data more homoscedastic and suitable for analysis.
- There is a positive correlation between year and selling price.
- The selling price also tends to increase with engine displacement and max power.
- Prices of budget cars, midrange cars and luxury car increase with Year.
- As the km driven increases, the selling price tends to decrease.
- There is no impact of fuel efficiency on selling price.
- The median price of automatic transmission cars is higher than that of manual transmission cars.
- The median price of test drive cars is very high when compared to other owner types.
- Prices of diesel cars are generally high. But prices of petrol cars with high horsepower are also high.


#### Analysis of Correlation Between Numeric Variables
```{r}
# Pairs plot for numeric variables
pairs(selling_price_in_10k ~ year + km_driven_in_10k + fuel_efficiency + engine + max_power + seats, data = car_details)

# Calculate correlation matrix for numeric variables
cor_mat = cor(car_details[, sapply(car_details, is.numeric)])
cor_mat

# Extract high correlation values from the upper triangle of the correlation 
# matrix (to remove redundant correlations caused by symmetry)
high_cor_indices = which(upper.tri(cor_mat) & cor_mat > 0.5, arr.ind = TRUE)

# Create table for high-correlation variables
high_cor_df = data.frame(
  row = rownames(cor_mat)[high_cor_indices[, 1]],
  column = colnames(cor_mat)[high_cor_indices[, 2]],
  correlation = cor_mat[high_cor_indices]
)

# Display the first few entries in the table
head(high_cor_df)
```

- From the above table of high-correlation variable pairs, we can see that the following variable pairs have correlations above 0.5:
  - ```max_power``` and ```selling_price``` have a high correlation of 0.6872307. Hence, selling price increases with max power.
  - ```max_power``` and ```engine``` have a high correlation of 0.6863027. This indicates that higher-displacement engines tend to be more powerful. 
  - ```seats``` and ```engine``` have high a correlation of 0.6631. This indicates that vehicles with more seats tend to have larger engines.

### Model Development and Validation

In this section, a model for predicting values of ```selling_price``` based on the values of the other variables is developed and the performance of the model is analyzed. 

#### Splitting data into train and test sets

<!-- # vif() does not run if perfectly multicollinear "alias" variables are present , -->
<!-- # and make and make_category variables will be perfectly multicollinear if "make" is not removed, -->
<!-- # from train_data and test_data -->

```{r}
set.seed(125) # For reproducibility
train_indices <- sample(nrow(car_details), size = 0.80 * nrow(car_details))
train_data <- car_details[train_indices, ]
test_data <- car_details[-train_indices, ]

# Remove `make` from train_data and test_data
train_data <- subset(train_data, select = -make)
test_data <- subset(test_data, select = -make)

# Check row counts to confirm split
nrow(train_data)
nrow(test_data)
```

#### Baseline Additive Linear Model (using all available predictors except ```make```)
```{r}
# Definition of "full" linear model
additive_model = lm(selling_price_in_10k ~ ., data = train_data)

# Model summary
summary(additive_model)

# Leave one out cross validation RMSE 
sqrt(mean((resid(additive_model) / (1 - hatvalues(additive_model))) ^ 2))

# Diagnostic plots
par(mfrow = c(1, 2))
plot(additive_model,which=c(1,2))

# Diagnostic tests
bp_test <- bptest(additive_model)
print(bp_test)

# Subset residuals for Shapiro-Wilk test (up to 5000 samples)
residual_subset = sample(residuals(additive_model), size = 5000)
shapiro_test = shapiro.test(residual_subset)
print(shapiro_test)

# Multicollinearity test
vif(additive_model)
```

The baseline additive linear model has a high R² value of 0.7107, indicating that approximately 71% of the variance in ```selling_price_in_10k``` is explained by the predictors.

Most predictors are statistically significant (p-value < 0.05), suggesting they contribute meaningfully to the model.
Exceptions are:

  - ```seller_typeTrustmark Dealer``` (p = 0.33)
  - ```ownerFourth & Above Owner``` (p = 0.14)
  - ```seats``` (p = 0.48)

From this initial model, it is apparent:

  - ```year``` is positively correlated with price (newer cars sell for higher prices)
  - ```engine```, ```max_power```, ```make_category:Luxury``` are positively correlated with selling prices (more powerful vehicles and luxury vehicles sell for more)
  - ```km_driven_in_10k```, ```fuelPetrol```, and ```fuel_efficiency``` are negatively correlated with selling price: higher mileage vehicles and petrol vehicles are associated with lower selling prices

Diagnostic testing for this model:

  - The Breusch-Pagan test yielded a very high test statistic of 1538.2, and a p-value less than $2.2*10^{-16}$, which strongly indicates heteroscedasticity. This is reflected by the "fat tails" in the QQ plot.
  - The Shapiro-Wilk test yielded a low p-value less than $2.2*10^{-16}$, which strongly rejects the null hypothesis that the residuals are normally distributed.

For this model, VIF analysis shows:

  - All VIFs are below 5, indicating no severe multicollinearity among predictors. However:
    - ```engine``` (VIF = 2.36) and ```fuel_efficiency``` (VIF = 1.80) have relatively higher multicollinearity (but they still within acceptable ranges).

#### Adding Interaction Terms: The Full Interaction Model
Below, the simple additive model is expanded with terms for all interactions between all variables (except for ```make```). An ANOVA test is then performed to give an initial comparison of the two models.
``` {r}
# Definition of full interaction model with all interaction terms
interaction_model <- lm(selling_price_in_10k ~ (.)^2, data = train_data)

# Model summary
print(head(coef(summary(interaction_model)), n = 50))

# ANOVA comparison of additive model and interaction model
anova_comparison <- anova(additive_model, interaction_model)
anova_comparison
```

The interaction model:

  - Has terms with NA coefficients that indicate linear dependencies or collinearity in the data, making them redundant for the model, such as ```year:ownerTest Drive Car```, ```seller_typeIndividual:make_categoryMidrange```, and ```transmissionManuHasal:ownerTest Drive Car```.
  - Has some low p-values, which are candidates for inclusion in the model
    - ```year:km_driven_in_10k``` (p<0.001): interaction between ```year``` and ```km_driven_in_10k```.
    - ```year:fuelPetrol``` (p<0.001): Interaction between ```year``` and ```fuelPetrol```.
    - ```year:seller_typeIndividual``` (p<0.001): Interaction between ```year``` and ```seller_typeIndividual```.
    - ```km_driven_in_10k:transmissionManual``` (p=0.006): Interaction between ```km_driven_in_10k``` and ```transmissionManual```.
    - ```fuelPetrol:fuel_efficiency``` (p=0.006): Interaction between ```fuelPetrol``` and ```fuel_efficiency```.
  - Has terms with high p-values, such as ```km_driven_in_10k:ownerFourth & Above Owner``` (p = 0.780). These variables are not statistically significantly likely to be adding predictive power to the model, and can potentially be pruned.
```fuelPetrol:seller_typeTrustmark Dealer``` (p = 0.276).
  - Has terms with low-magnitude coefficients, that may not be meaningfully impacting the model (such as ```fuel_efficiency:engine``` with -0.002849).

From the results of the ANOVA test comparing the two models, we see:

  - The interaction model has a large reduction in RSS from 3835608 to 1509381.
  - There is highly significant improvement: F=82.2227, $p<2.2×10^{−16}$.
  - The interaction terms drastically improve the model fit.

We can see that it appears that there may be some interaction terms that are worth including in the model.

#### Stepwise Selection to Prune Variables
In the code below, the interaction model is trimmed using stepwise selection. Both AIC and BIC-based stepwise selection models are used. All models are compared with an analysis of variance test and with comparison of AIC, BIC, Adjusted R², and CV RMSE metrics.
```{r}
# Define the sample size for BIC computation
n <- nrow(train_data)

# Stepwise selection for interaction model
backward_aic_interaction <- step(interaction_model, direction = "backward", trace = 0)
backward_bic_interaction <- step(interaction_model, direction = "backward", k = log(n), trace = 0)

# Output summaries of both models
summary(backward_aic_interaction)
summary(backward_bic_interaction)

# Count the number of variables (including the intercept) in both models
num_variables_aic <- length(coef(backward_aic_interaction))
num_variables_bic <- length(coef(backward_bic_interaction)) 

# Print the number of variables
print(num_variables_aic)
print(num_variables_bic)

# Set the significance level
significance_level <- 0.05

# Extract the summary of the models
summary_aic <- summary(backward_aic_interaction)
summary_bic <- summary(backward_bic_interaction)

# Count the number of statistically significant variables for each model
significant_vars_aic <- sum(summary_aic$coefficients[, 4] < significance_level)  # p-values in the 4th column
significant_vars_bic <- sum(summary_bic$coefficients[, 4] < significance_level) 

# Print the number of statistically significant variables
print(significant_vars_aic)
print(significant_vars_bic)
```

Observations about the AIC and BIC-pruned interaction models:

  - The AIC model includes more interaction terms and variables than the BIC model. 
  - The estimated coefficients are different in the two models. For example, the coefficient of ```ownerFourth``` & ```Above Owner``` is 3.473e+01 in the BIC model, whereas it was 2.966e+03 in the AIC model.
  - In the AIC model, more variables are statistically significant (p-value < 0.05) compared to the BIC model
  - Both models have similar residual standard errors (around 17) and adjusted R² values (around 0.88), indicating that the goodness-of-fit measures are almost the same for both models.
  
  
##### ANOVA Comparison of All Pruned and Unpruned Models
```{r}
# Define the models for comparison
models <- list(
  additive_model, interaction_model,
  backward_aic_interaction, backward_bic_interaction
)

# Perform ANOVA comparisons between models
anova_additive_interaction <- anova(additive_model, interaction_model)
anova_additive_backward_aic <- anova(additive_model, backward_aic_interaction)
anova_additive_backward_bic <- anova(additive_model, backward_bic_interaction)
anova_interaction_backward_aic <- anova(interaction_model, backward_aic_interaction)
anova_interaction_backward_bic <- anova(interaction_model, backward_bic_interaction)
anova_backward_aic_backward_bic <- anova(backward_aic_interaction, backward_bic_interaction)

# Test 1: ANOVA comparison between Additive Model and Interaction Model:
print(anova_additive_interaction)
```

  - Model 1 (the interaction model) has an RSS of 3,835,608. Model 2 (the additive model) has an RSS of 1,509,381. The difference in RSS between the two models is 2,326,227. A lower RSS for model 2 indicates that the interaction model does a better job of fitting the data.
  - The F-statistic is 82.228, which is large. This suggests that the interaction model improves the fit compared to the additive model.
  - The p-value is extremely small (< 2.2e-16), which indicates that the difference in fit between the two models is statistically significant.
  - From these results, we conclude that **the interaction model improves upon the additive model**.

```{r}
# Test 2: ANOVA comparison between additive model and backward AIC interaction model:
print(anova_additive_backward_aic)
```

  - Model 1 (the additive model) has an RSS of 3,835,608. Model 2 (the backward-AIC-selected interaction model) has an RSS of 1,521,380. A lower RSS in Model 2 indicates a better fit of the data by the second model.
  - The F-statistic is 146.99, which is quite large. This suggests that the addition of (pruned) interactions is beneficial in explaining the variance in the selling price compared to the additive model.
  - The p-value is extremely small (< 2.2e-16), which indicates that the difference in fit between the two models is statistically significant. This means that the backward AIC interaction model significantly improves the model fit compared to the additive model.
  - From these results we conclude that **the AIC-pruned interaction model improves upon the additive model**.

```{r}
# Test 3: ANOVA comparison between additive model and backward BIC interaction model:
print(anova_additive_backward_bic)
```

  - Model 1 (the additive model) has an RSS of 3,835,608. Model 2 (the backward-BIC-selected interaction model) has an RSS of 1,556,098. A lower RSS in model 2 indicates a better fit of the data by model 2. 
  - The F-statistic is 284.57, which is quite large. This suggests that the addition of BIC-pruned interactions is significantly improving the model fit compared to the additive model.
  - The p-value is extremely small (< 2.2e-16), which indicates that the difference in fit between the two models is statistically significant. This means that the backward BIC  interaction model significantly improves the model fit compared to the additive model.
  - From these results we conclude that **the BIC-pruned interaction model improves upon the additive model**.

```{r}
# Test 4: ANOVA comparison between interaction model and backward AIC interaction Model:
print(anova_interaction_backward_aic)
```

  - Model 1 (the full interaction model) has an RSS of 1,509,381. Model 2 (the backward-AIC-selected interaction model) has an RSS of 1,521,380. The difference in RSS is minimal, indicating that the interaction backward AIC model does not significantly improve the fit compared to the Interaction Model.
  - The F-statistic is 0.9567, which is close to 1. This suggests that the addition of interactions in the backward AIC interaction modl does not result in a better fit.
  - The p-value is 0.5523, which is quite large. This indicates that the difference in fit between the two models is not statistically significant.
  - From these results, we **cannot conclude that backward AIC pruning improves the interaction model**.

```{r}
# Test 5: ANOVA comparison between interaction model and backward BIC interaction model:
print(anova_interaction_backward_bic)
```

  - Model 1 (the full interaction model) has an RSS of 1,509,381. Model 2 (the backward-BIC-selected interaction model) has an RSS of 1,556,098. A lower RSS in model 1 indicates that the interaction model provides a slightly better fit compared to the backward-BIC-pruned model. 
  - The F-statistic is 2.2882, which suggests a small but non-negligible improvement in the model fit when switching from the interaction model to the BIC-pruned model. 
  - The p-value is 7.583e-09, which is very small. This indicates that the difference in fit between the two models is statistically significant.
  - We can conclude that **backward BIC-based pruning improves the interaction model, but the improvement is small**. 

```{r}
# Test 6: ANOVA comparison between backward AIC interaction moel and backward BIC interaction model:
print(anova_backward_aic_backward_bic)
```

  - Model 1 (the backward-AIC-selected interaction model) has an RSS of 1,521,380. Model 2 (the backward-BIC-selected interaction model) has an RSS of 1,556,098. A lower RSS in Model 1 indicates a better fit by the backward AIC Model.
  - The F-statistic is 4.4102, which suggests that the interaction backward AIC model improves the fit compared to the interaction backward BIC model.
  - The p-value is 2.382e-13, which is extremely small. This indicates that the difference in fit between the two models is statistically significant.
  - We can conclude that **backward AIC-based pruning is an improvement upon backward-BIC-pruning**. 
  
##### Metric-Based Comparison of Models
```{r}
# Function to compute Adjusted R-squared and CV RMSE
compute_metrics <- function(model, data) {
  adj_r2 <- summary(model)$adj.r.squared
  # CV RMSE using LOOCV
  cv_rmse <- sqrt(mean((resid(model) / (1 - hatvalues(model))) ^ 2))
  return(list(adj_r2 = adj_r2, cv_rmse = cv_rmse))
}

# Collect metrics for all models mentioned
models <- list(
  additive_model, interaction_model,
  backward_aic_interaction, backward_bic_interaction
)

model_names <- c(
  "Additive", "Interaction",
  "Backward AIC Interaction", "Backward BIC Interaction"
)

# Compare AIC, BIC, Adjusted R2, and CV RMSE
metrics <- data.frame(
  Model = model_names,
  AIC = sapply(models, AIC),
  BIC = sapply(models, BIC),
  Adjusted_R2 = sapply(models, function(m) compute_metrics(m, train_data)$adj_r2),
  CV_RMSE = sapply(models, function(m) compute_metrics(m, train_data)$cv_rmse)
)

# Print the comparison metrics
print(metrics)
```

From these metrics we see:

  - Best AIC: The lowest AIC is for the backward AIC interaction model with a value of 45098.50.
  - Best BIC: The lowest BIC is for the backward AIC interaction model with a value of 45571.78.
  - Best Adjusted R²: The highest adjusted R² is for the backward AIC interaction model with a value of 0.8837199.
  
##### Model Selection
Based on these results, we **select the backward AIC interaction model to be our best model** for this stage. 

#### Diagnostics for Best Model

##### Multicollinearity
```{r}
# Multicollinearity test

# Check for aliased variables
alias_results <- alias(backward_aic_interaction)
alias_results

#vif(backward_aic_interaction) 
```

The backward AIC interaction model has variables that are perfectly multicollinear. VIF analysis using the ```vif()``` method cannot be done until these variables are removed from the model. 

Based on the ```alias()``` results, which returns perfectly-collinear variables, there are a number of terms used in the model that exhibit perfect collinearity with other terms and should be removed. 

  - ```ownerTest Drive Car:make_categoryLuxury```
  - ```ownerFourth & Above Owner:make_categoryMidrange```
  - ```ownerTest Drive Car:make_categoryMidrange```
  - ```ownerFourth & Above Owner```
  - ```ownerSecond Owner```
  - ```ownerTest Drive Car```
  - ```ownerThird Owner```
  - ```km_driven_in_10k:fuelPetrol```
  - ```fuelPetrol:fuel_efficiency```
  - ```fuelPetrol:seats```
  - ```fuelPetrol:make_categoryLuxury```
  - ```fuelPetrol:make_categoryMidrange```
  - ```seller_typeIndividual```
  - ```seller_typeTrustmark Dealer```
  - ```seller_typeIndividual:fuel_efficiency```
  - ```seller_typeTrustmark Dealer:fuel_efficiency```
  - ```transmissionManual```
  - ```transmissionManual:ownerFourth & Above Owner```
  - ```transmissionManual:ownerSecond Owner```
  - ```transmissionManual:ownerTest Drive Car```
  - ```transmissionManual:ownerThird Owner```
  - ```transmissionManual:engine```
  - ```transmissionManual:make_categoryLuxury```
  - ```transmissionManual:make_categoryMidrange```
  - ```transmissionManual:fuel_efficiency```
  - ```transmissionManual:seats```
  - ```engine```
  - ```max_power```
  - ```fuel_efficiency```
  - ```fuel_efficiency:engine```
  - ```fuel_efficiency:max_power```
  - ```fuel_efficiency:seats```
  - ```fuel_efficiency:make_category```
  - ```engine:max_power```
  - ```engine:make_category```
  - ```max_power:seats```
  - ```max_power:make_category```
  - ```seats:make_category```

Fitting the model again without these variables:
```{r}
# Revised model excluding the collinear terms

# In order to specify interaction terms for categorical variables, you need to make dummy variables for them

# revised__aic_interaction <- lm(selling_price_in_10k ~ year + km_driven_in_10k + fuel + seller_type +
#                     transmission + owner + year:km_driven_in_10k + year:fuel +
#                     year:seller_type + year:transmission + year:make_category +
#                     km_driven_in_10k:transmission + km_driven_in_10k:fuel_efficiency +
#                     km_driven_in_10k:make_category + fuel:fuel_efficiency + fuel:make_category +
#                     seller_type:fuel_efficiency + seller_type:engine + transmission:owner +
#                     transmission:engine + owner:fuel_efficiency + owner:make_category +
#                     fuel_efficiency:engine + fuel_efficiency:max_power +
#                     fuel_efficiency:make_category + engine:max_power + engine:make_category + 
#                     max_power:seats + seats:make_category + 
#                     transmissionManual:fuel_efficiency + 
#                     transmissionManual:engine + 
#                     transmissionManual:seats + 
#                     transmissionManual:make_categoryLuxury + 
#                     transmissionManual:make_categoryMidrange, data = train_data)

# Check again for aliased variables
#alias_results <- alias(revised_backward_aic_interaction)
#alias_results
```

```{r}
# VIF test (can only be performed once all perfectly multicollinear variables are removed)
# vif(revised_backward_aic_interaction)
```

##### Other Diagnostics
```{r}
# Diagnostic plots
par(mfrow = c(1, 2))
plot(backward_aic_interaction, which=c(1,2))

# Diagnostic tests
bp_test <- bptest(backward_aic_interaction)
print(bp_test)

# Subset residuals for Shapiro-Wilk test (up to 5000 samples)
residual_subset = sample(residuals(backward_aic_interaction), size = 5000)
shapiro_test = shapiro.test(residual_subset)
print(shapiro_test)
```

From the above diagnostics, it is clear that there are assumption violations in the model still. 

#### Addressing Heteroscedasticity
<!-- ##### Log Transformation of Reponse Variable -->
<!-- ```{r} -->
<!-- # Try log response of selling_price -->
<!-- # Add column for log of response -->
<!-- train_data$log_selling_price_in_10k = log(train_data$selling_price_in_10k) -->
<!-- test_data$log_selling_price_in_10k = log(test_data$selling_price_in_10k) -->


<!-- ``` -->

##### Weighted Least Squares (WLS) regression
<!-- ```{r} -->
<!-- # Try weighted least squares (wls) regression -->
<!-- # Get the fitted values for the full model -->
<!-- fitted_full_model = fitted(full_model) -->

<!-- # Compute the weights based on the fitted values (inverse of the squared fitted values) -->
<!-- weights = 1 / (fitted_full_model^2) -->

<!-- # Weighted least squares model using the full model formula and the computed weights -->
<!-- weighted_model = lm(formula = formula(full_model), data = train_data, weights = weights) -->

<!-- # Model summary -->
<!-- summary(weighted_model) -->

<!-- ``` -->

##### Comparison of log transformation of response and wls regression
``` {r}
# Compare the two methods of dealing with heteroscedasticity

```

 
#### Refitting the Model Without Influential Points
```{r}
# Remove influential points and refit best model

```





<!-- # Old code is here for now (copy pased from old version) -->

<!-- # Subset out influential points and redo the model -->

<!-- # Fit the bic_int_model on the dataset with influential points removed (train_data_filtered) -->
<!-- #bic_int_model_refitted = step(lm(selling_price_in_10k ~ year + make_category + max_power*fuel + transmission*seller_type + owner + engine, data = train_data_filtered), direction="both", k=log(n), trace=0) -->

<!-- # Model summary -->
<!-- #summary(bic_int_model_refitted) -->

<!-- ``` -->

<!-- ``` {r} -->
<!-- # Check if WLS regression fixes the full_add_model more than log transformation of the response -->

<!-- # Get the fitted values for the full model -->
<!-- fitted_full_model = fitted(full_model) -->

<!-- # Compute the weights based on the fitted values (inverse of the squared fitted values) -->
<!-- weights = 1 / (fitted_full_model^2) -->

<!-- # Weighted least squares model using the full model formula and the computed weights -->
<!-- weighted_model = lm(formula = formula(full_model), data = train_data, weights = weights) -->

<!-- # Model summary -->
<!-- summary(weighted_model) -->


<!-- # Diagnostics for WLS Model: -->

<!-- # 1. Residuals vs Fitted Plot (check for homoscedasticity) -->
<!-- par(mfrow = c(1, 2)) -->
<!-- plot(weighted_model, which = 1)  # Residuals vs Fitted -->

<!-- # 2. Normal Q-Q Plot (check for normality of residuals) -->
<!-- plot(weighted_model, which = 2)  # Normal Q-Q -->

<!-- # 3. Breusch-Pagan test for heteroscedasticity -->
<!-- bp_test = bptest(weighted_model) -->
<!-- cat("Breusch-Pagan Test for Heteroscedasticity:\n") -->
<!-- print(bp_test) -->

<!-- # 4. Shapiro-Wilk test for normality of residuals -->
<!-- # Subset residuals for Shapiro-Wilk test (up to 5000 samples) -->
<!-- residual_subset_weighted_model = sample(residuals(weighted_model), size = 5000) -->
<!-- # Perform Shapiro-Wilk test on the subset of residuals -->
<!-- shapiro_test_weighted_model = shapiro.test(residual_subset_weighted_model) -->
<!-- cat("Shapiro-Wilk Normality Test for Residuals (Weighted Model):\n") -->
<!-- print(shapiro_test_weighted_model) -->

<!-- # 5. Variance Inflation Factor (VIF) for multicollinearity -->
<!-- vif_test = vif(weighted_model) -->
<!-- cat("Variance Inflation Factors (VIF) for Multicollinearity:\n") -->
<!-- print(vif_test) -->

<!-- # 6. Leave-One-Out Cross-Validation RMSE (for model comparison) -->
<!-- rmse_weighted_model = sqrt(mean((resid(weighted_model) / (1 - hatvalues(weighted_model)))^2)) -->
<!-- cat("Leave-One-Out Cross-Validation RMSE for Weighted Model:\n") -->
<!-- print(rmse_weighted_model) -->

<!-- ``` -->

<!-- #### Logarithmic transformation of response variable -->

<!-- - From the previous Fitted vs Residual plot we can see there is a pattern in the residuals and the constant assumption is violated. -->
<!-- - Logarithmic transformation can make the positively skewed distribution of selling price to be normally distributed and makes it more suitable for model building and for stabilizing the variance. -->

<!-- ```{r} -->
<!-- train_data$selling_price_in_10k = log(train_data$selling_price_in_10k) -->
<!-- test_data$selling_price_in_10k = log(test_data$selling_price_in_10k) -->
<!-- ``` -->


<!-- #### Additive "full" linear model (using all available predictors except ```make```) | with BIC -->
<!-- ```{r} -->
<!-- # Definition of "full" linear model with BIC-based stepwise model selection starting from full model (both directions) -->
<!-- n= nrow(train_data) -->
<!-- bic_full_add_model = step(lm(selling_price_in_10k ~ .-make, data = train_data),direction="both",k=log(n),trace=0) -->

<!-- # Model summary -->
<!-- summary(bic_full_add_model) -->

<!-- #Number of parameters -->
<!-- length(coef(bic_full_add_model)) -->

<!-- #Leave one out cross validation RMSE -->
<!-- sqrt(mean((resid(bic_full_add_model) / (1 - hatvalues(bic_full_add_model))) ^ 2)) -->

<!-- # Diagnostic plots -->
<!-- par(mfrow = c(1, 2)) -->
<!-- plot(bic_full_add_model,which=c(1,2)) -->

<!-- # Diagnostic tests -->
<!-- bp_test = bptest(bic_full_add_model) -->
<!-- print(bp_test) -->

<!-- # Subset residuals for Shapiro-Wilk test (up to 5000 samples) -->
<!-- residual_subset = sample(residuals(bic_full_add_model), size = 5000) -->
<!-- shapiro_test = shapiro.test(residual_subset) -->
<!-- print(shapiro_test) -->

<!-- # Multicollinearity test -->
<!-- vif(bic_full_add_model) -->
<!-- ``` -->

<!-- ``` {r} -->
<!-- # Comparing log transformation of the reponse to WLS regression -->
<!-- # Perform ANOVA to compare weighted_model and bic_full_add_model -->
<!-- anova_comparison <- anova(weighted_model, bic_full_add_model) -->

<!-- # Display the ANOVA comparison results -->
<!-- anova_comparison -->
<!-- ``` -->

<!-- <!-- The WLS model outperforms the log-transformed model based on multiple criteria: --> -->

<!-- <!--     It has a higher R-squared value, indicating a better fit to the data. --> -->
<!-- <!--     The residual diagnostics (Shapiro-Wilk and Breusch-Pagan tests) suggest that the WLS model addresses heteroscedasticity better than the log-transformed model, although there are still some issues with normality. --> -->
<!-- <!--     The ANOVA test confirms that the WLS model is a better fit for the data, as indicated by a much lower RSS. --> -->

<!-- |                                                              | Adjusted R^2 | Number of <br>parameters | Breusch-Pagan test                                         | Shapiro-Wilk test<br>(with 5k sample residuals)   | VIF>5 | Non significant <br>predictors(pvalue > 0.05) | LOOCV<br>RMSE | -->
<!-- |--------------------------------------------------------------|--------------|--------------------------|------------------------------------------------------------|---------------------------------------------------|-------|-----------------------------------------------|---------------| -->
<!-- | Full additive model with BIC<br>(Excluding "make" predictor) | 0.8469423    | 17                       | Constant variance assumption <br>violated with BP = 372.41 | Normality assumption violated<br>with W = 0.98173 | None  | seller_typeTrustmark Dealer                   | 0.2914511     | -->
<!-- |                                                              |              |                          |                                                            |                                                   |       |                                               |               | -->

<!-- - The "full" linear model has a high $R^2$ value of 0.8469423, indicating that 84.69% of the variance in ```selling_price_in_10k``` is explained by the predictors. -->

<!-- - Most predictors are statistically significant (p-value < 0.05), suggesting they contribute meaningfully to the model. -->
<!-- Except  ```seller_typeTrustmark Dealer``` (p = 0.165779) -->

<!-- - Diagnostic testing for this model: -->
<!--   - The Breusch-Pagan test yielded a very high test statistic of 372.41 and a p-value less than $2.2*10^{-16}$ which rejects the null hypothesis that constant variance exists in residuals -->

<!--   - The Shapiro-Wilk test with 5000 sample residuals yielded a low p-value less than $2.2*10^{-16}$, which rejects the null hypothesis that the residuals are normally distributed. -->

<!-- <!-- We can add explanation and/or tabulation to summarize the result --> -->

<!-- #### "Small additive model" with BIC-based stepwise feature selection -->
<!-- ```{r} -->
<!-- bic_small_add_model = step(lm(selling_price_in_10k ~ year + make_category + max_power + transmission + fuel + seller_type + owner +engine, data = train_data),direction="both",k=log(n),trace=0) -->

<!-- # Model summary -->
<!-- summary(bic_small_add_model) -->

<!-- #Number of parameters -->
<!-- length(coef(bic_small_add_model)) -->

<!-- #Leave one out cross validation RMSE -->
<!-- sqrt(mean((resid(bic_small_add_model) / (1 - hatvalues(bic_small_add_model))) ^ 2)) -->

<!-- # Diagnostic plots -->
<!-- par(mfrow = c(1, 2)) -->
<!-- plot(bic_small_add_model,which=c(1,2)) -->

<!-- # Diagnostic tests -->
<!-- bptest(bic_small_add_model) -->


<!-- # Subset residuals for Shapiro-Wilk test (up to 5000 samples) -->
<!-- residual_subset = sample(residuals(bic_small_add_model), size = 5000) -->
<!-- shapiro.test(residual_subset) -->


<!-- # Multicollinearity test -->
<!-- vif(bic_small_add_model) -->
<!-- ``` -->


<!-- #### ANOVA of Small and Full additive models -->
<!-- ```{r} -->
<!-- anova(bic_small_add_model, bic_full_add_model) -->
<!-- ``` -->

<!-- - From the above Analysis of Variance(ANOVA) result we can say that Full additive model is statistically better than small additive model, based on the high F-test low p_value and lower RSS. -->
<!-- - Full additive model has lower RSS (446.00) than small additive model (453.14), indicating that full additive model fits the data better. -->
<!-- - Low p_value indicates that the small additive model is NOT sufficient in explaining the variance of the response variable. -->
<!-- - Hence we reject the null hypothesis that H0: small additive model is sufficient in explaining the variance of the response variable. -->
<!-- - We also understand that full model is more complex with 17 parameters is harder to interpret than the small model. -->
<!-- - Hence **we can select the small model since the difference in RSS is very small** (`r 453.14-446.00`) **and it is comparitively easier to interpret** -->

<!-- ### Influential points -->
<!-- ```{r} -->
<!-- indicies_to_exclude = unname(which(cooks.distance(bic_small_add_model) > 4/length(cooks.distance(bic_small_add_model)))) -->
<!-- train_data_filtered = train_data[-indicies_to_exclude,] -->
<!-- #Number of excluded observations -->
<!-- nrow(train_data) - nrow(train_data_filtered) -->
<!-- ``` -->

<!-- ### Refitting the BIC Small additive model without influential points -->
<!-- ```{r} -->
<!-- n= nrow(train_data_filtered) -->
<!-- refitted_bic_small_add_model = lm(formula = formula(bic_small_add_model), data = train_data_filtered) -->

<!-- # Model summary -->
<!-- summary(refitted_bic_small_add_model) -->

<!-- #Number of parameters -->
<!-- length(coef(refitted_bic_small_add_model)) -->

<!-- #Leave one out cross validation RMSE -->
<!-- sqrt(mean((resid(refitted_bic_small_add_model) / (1 - hatvalues(refitted_bic_small_add_model))) ^ 2)) -->

<!-- # Diagnostic plots -->
<!-- par(mfrow = c(1, 2)) -->
<!-- plot(refitted_bic_small_add_model,which=c(1,2)) -->

<!-- # Diagnostic tests -->
<!-- bptest(refitted_bic_small_add_model) -->


<!-- # Subset residuals for Shapiro-Wilk test (up to 5000 samples) -->
<!-- residual_subset = sample(residuals(refitted_bic_small_add_model), size = 5000) -->
<!-- shapiro.test(residual_subset) -->


<!-- # Multicollinearity test -->
<!-- vif(refitted_bic_small_add_model) -->
<!-- ``` -->

<!-- <!-- We can add explanation and/or tabulation to summarize the result. -->
<!-- R^2 is better -->
<!-- num of  params gone down by 1 -->
<!-- BP value is better, but p_value of BP test is still low -->
<!-- --> -->

<!-- #### "Interaction model" with BIC-based stepwise feature selection -->

<!-- - From the above results we can see that the constant variance assumption is violated for all the above models. -->
<!-- - Hence there could be some more possibilities to improve the model either through interaction terms or through predictor transformations. -->
<!-- - In the following model the interactions terms are used based the results of data analysis -->

<!-- ```{r} -->
<!-- bic_int_model = step(lm(selling_price_in_10k ~ year + make_category + max_power*fuel + transmission*seller_type + owner + engine, data = train_data),direction="both",k=log(n),trace=0) -->

<!-- # Model summary -->
<!-- summary(bic_int_model) -->

<!-- #Number of parameters -->
<!-- length(coef(bic_int_model)) -->

<!-- #Leave one out cross validation RMSE -->
<!-- sqrt(mean((resid(bic_int_model) / (1 - hatvalues(bic_int_model))) ^ 2)) -->

<!-- # Diagnostic plots -->
<!-- par(mfrow = c(1, 2)) -->
<!-- plot(bic_int_model,which=c(1,2)) -->

<!-- # Diagnostic tests -->
<!-- bptest(bic_int_model) -->


<!-- # Subset residuals for Shapiro-Wilk test (up to 5000 samples) -->
<!-- residual_subset = sample(residuals(bic_int_model), size = 5000) -->
<!-- shapiro.test(residual_subset) -->


<!-- # Multicollinearity test -->
<!-- vif(bic_int_model) -->
<!-- ``` -->

<!-- ```{r} -->
<!-- # bic_int_model_refitted -->

<!-- # Fit the bic_int_model on the dataset with influential points removed (train_data_filtered) -->
<!-- bic_int_model_refitted = step(lm(selling_price_in_10k ~ year + make_category + max_power*fuel + transmission*seller_type + owner + engine, -->
<!--                                  data = train_data_filtered), direction="both", k=log(n), trace=0) -->

<!-- # Model summary -->
<!-- summary(bic_int_model_refitted) -->
<!-- ``` -->

<!-- #### ANOVA of Small additive model and Interaction model -->
<!-- - We cannot compare the refitted_bic_small_add_model with interaction model because the data sets will differ and the anova test will give an error. -->
<!-- ```{r} -->
<!-- anova(bic_small_add_model, bic_int_model) -->
<!-- ``` -->
<!-- - Statistically low p_value suggests we can reject the null hypothesis that bic_small_add_model is sufficient in explaining the response variable and the interaction model is better. -->
<!-- - Again, here the difference in the RSS of the model is very low.(`r 453.14-451.93`) -->
<!-- - Hence we can go ahead with bic_small_add_model or in turn use **refitted_bic_small_add_model**, which has comparatively low test statistic of BP = 251.66 when compared to the interaction model which has a BP=378.51. (Higher the value of test statistic, lower the p_value) -->

<!-- #### Weighted least square approach -->
<!-- - In all of the above models we can see that the constant variance assumption is violated. -->
<!-- - To resolve this we can try weighted linear regression approach -->
<!-- - In weighted linear regression, observations with higher weights contribute more to the estimation of the regression coefficients, while observations with lower weights have less influence. -->
<!-- - This approach is often used when there is non-constant variance in the residuals or when certain observations are more reliable or important than others. -->

<!-- ```{r} -->
<!-- # Try making refitted versions of full additive model, interacitve model, and wls model using the dataset with the influential points removed -->
<!-- # Refit full_add_model on the filtered dataset -->
<!-- refitted_full_add_model <- lm(selling_price_in_10k ~ (make + year + km_driven_in_10k + fuel + -->
<!--                                                      seller_type + transmission + owner + fuel_efficiency + -->
<!--                                                      engine + max_power + seats + make_category) - make, -->
<!--                                data = train_data_filtered) -->

<!-- # Refit bic_int_model on the filtered dataset -->
<!-- refitted_bic_int_model <- lm(selling_price_in_10k ~ year + make_category + max_power + transmission + -->
<!--                               fuel + seller_type + owner + engine + -->
<!--                               fuel_efficiency + km_driven_in_10k + seats, -->
<!--                               data = train_data_filtered) -->

<!-- # Refit weighted_model on the filtered dataset -->
<!-- refitted_weighted_model <- lm(selling_price_in_10k ~ year + make_category + max_power + transmission + -->
<!--                                fuel + seller_type + owner + engine, -->
<!--                                data = train_data_filtered, weights = train_data_filtered$weight_variable)  # Replace "weight_variable" with the appropriate column for weights -->

<!-- # Output model summaries -->
<!-- summary(refitted_full_add_model) -->
<!-- summary(refitted_bic_int_model) -->
<!-- summary(refitted_weighted_model) -->

<!-- ``` -->



<!-- ```{r} -->
<!-- fitted = fitted(refitted_bic_small_add_model) -->
<!-- weights = 1 / (fitted^2) -->
<!-- weighted_model = lm(formula=formula(refitted_bic_small_add_model),data=train_data_filtered,weights=weights) -->

<!-- # Model summary -->
<!-- summary(weighted_model) -->

<!-- #Number of parameters -->
<!-- length(coef(weighted_model)) -->

<!-- #Leave one out cross validation RMSE -->
<!-- sqrt(mean((resid(weighted_model) / (1 - hatvalues(weighted_model))) ^ 2)) -->

<!-- # Diagnostic plots -->
<!-- #par(mfrow = c(1, 2)) -->
<!-- plot(weighted_model,which=c(1,2)) -->

<!-- # Diagnostic tests -->
<!-- bptest(weighted_model) -->


<!-- # Subset residuals for Shapiro-Wilk test (up to 5000 samples) -->
<!-- residual_subset = sample(residuals(weighted_model), size = 5000) -->
<!-- shapiro.test(residual_subset) -->


<!-- # Multicollinearity test -->
<!-- vif(weighted_model) -->
<!-- ``` -->

<!-- <!--- R^2 has increased, BP value has come down, but p_value of BP test is still low --> -->

<!-- ```{r} -->

<!-- # Compute AIC and BIC for all models -->
<!-- model_comparisons <- data.frame( -->
<!--   Model = c("full_model", "bic_full_add_model", "bic_small_add_model", -->
<!--             "refitted_bic_small_add_model", "bic_int_model", "weighted_model", -->
<!--             "refitted_full_add_model", "refitted_bic_int_model", -->
<!--             "refitted_weighted_model", "bic_int_model_refitted"),  # Added new model here -->
<!--   AIC = c(AIC(full_model), AIC(bic_full_add_model), AIC(bic_small_add_model), -->
<!--           AIC(refitted_bic_small_add_model), AIC(bic_int_model), AIC(weighted_model), -->
<!--           AIC(refitted_full_add_model), AIC(refitted_bic_int_model), -->
<!--           AIC(refitted_weighted_model), AIC(bic_int_model_refitted)),  # AIC for the new model -->
<!--   BIC = c(BIC(full_model), BIC(bic_full_add_model), BIC(bic_small_add_model), -->
<!--           BIC(refitted_bic_small_add_model), BIC(bic_int_model), BIC(weighted_model), -->
<!--           BIC(refitted_full_add_model), BIC(refitted_bic_int_model), -->
<!--           BIC(refitted_weighted_model), BIC(bic_int_model_refitted))  # BIC for the new model -->
<!-- ) -->

<!-- # Display the results -->
<!-- model_comparisons -->

<!-- # Perform ANOVA for all models -->
<!-- anova_comparison <- anova( -->
<!--   refitted_bic_small_add_model, -->
<!--   refitted_full_add_model, -->
<!--   refitted_bic_int_model, -->
<!--   refitted_weighted_model, -->
<!--   bic_int_model_refitted -->
<!-- ) -->

<!-- anova_comparison -->

<!-- ``` -->


<!-- ## Results -->

<!-- ## Discussion -->

<!-- ## Appendix -->


